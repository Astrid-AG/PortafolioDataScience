{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pr√°cticas de Computer Vision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Establecemos nuestras credenciales \n",
    "key= 'b705236668a345c8961fa232ae172ad1'\n",
    "endpoint= 'https://lab1-cv.cognitiveservices.azure.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instalamos \n",
    "!pip install --upgrade azure-cognitiveservices-vision-computervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectamos con azure\n",
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "client= ComputerVisionClient(endpoint,CognitiveServicesCredentials(key))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vision\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#Obtenemos la imagen \n",
    "image_path='./data-vision/depositphotos_183023002-stock-photo-friends-meeting-group-happy-people.jpg'\n",
    "image_stream = open(image_path,'rb')\n",
    "description= client.describe_image_in_stream(image_stream)\n",
    "print(description)\n",
    "\n",
    "vision.show_image_caption(image_path,description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path='./data-vision/personas-felices.png'\n",
    "image_stream = open(image_path,'rb')\n",
    "description= client.describe_image_in_stream(image_stream)\n",
    "print(description)\n",
    "\n",
    "vision.show_image_caption(image_path,description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path='./data-vision/depositphotos_183023002-stock-photo-friends-meeting-group-happy-people.jpg'\n",
    "\n",
    "features= ['Tags', 'Description', 'Adult', 'Objects', 'Faces']\n",
    "\n",
    "image_stream = open(image_path,'rb')\n",
    "analisis= client.analyze_image_in_stream(image_stream, visual_features=features)\n",
    "\n",
    "vision.show_image_analysis(image_path, analisis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instalar\n",
    "!pip install --upgrade azure-cognitiveservices-vision-face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key= 'c25982bbadfa4086948524b86d83b1b6'\n",
    "endpoint = 'https://face-dr-lab02.cognitiveservices.azure.com/'\n",
    "\n",
    "# Conectamos con azure\n",
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "client= FaceClient(endpoint,CognitiveServicesCredentials(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faces\n",
    "import os\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path='./data-vision/depositphotos_183023002-stock-photo-friends-meeting-group-happy-people.jpg'\n",
    "image_stream = open(image_path,'rb')\n",
    "detected_faces= client.face.detect_with_stream( image=image_stream)\n",
    "faces.show_faces(image_path,detected_faces, show_id=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path='./data-vision/personas-felices.png'\n",
    "image_stream = open(image_path,'rb')\n",
    "\n",
    "attributes= ['age', 'emotion']\n",
    "detected_faces= client.face.detect_with_stream(image=image_stream, return_face_attributes=attributes)\n",
    "\n",
    "faces.show_face_attributes(image_path,detected_faces)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "535f7c689ab2befb563c2c0ac9539fce3167d9878e4255f884b6e0cc65ea596a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
